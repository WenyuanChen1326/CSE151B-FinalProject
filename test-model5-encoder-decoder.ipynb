{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-22T20:52:30.656087Z","iopub.status.idle":"2022-05-22T20:52:30.656538Z","shell.execute_reply.started":"2022-05-22T20:52:30.656348Z","shell.execute_reply":"2022-05-22T20:52:30.656369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os, os.path \nimport numpy \nfrom glob import glob\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:30.663387Z","iopub.execute_input":"2022-05-22T20:52:30.663684Z","iopub.status.idle":"2022-05-22T20:52:32.518884Z","shell.execute_reply.started":"2022-05-22T20:52:30.663650Z","shell.execute_reply":"2022-05-22T20:52:32.517863Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install pickle5","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:32.520832Z","iopub.execute_input":"2022-05-22T20:52:32.521134Z","iopub.status.idle":"2022-05-22T20:52:47.294368Z","shell.execute_reply.started":"2022-05-22T20:52:32.521087Z","shell.execute_reply":"2022-05-22T20:52:47.293598Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pickle5 as pickle","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:47.295613Z","iopub.execute_input":"2022-05-22T20:52:47.295885Z","iopub.status.idle":"2022-05-22T20:52:47.308516Z","shell.execute_reply.started":"2022-05-22T20:52:47.295854Z","shell.execute_reply":"2022-05-22T20:52:47.307692Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport pickle5 as pickle\nimport numpy as np\n\nROOT_PATH = \"../input/\"\n\ncities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\nsplits = [\"train\", \"test\"]\n\ndef get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n    if split==\"train\":\n        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs)\n\n        outputs = None\n    \n        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n        outputs = pickle.load(open(f_out, \"rb\"))\n        outputs = np.asarray(outputs)\n        \n    elif split==\"test\":\n        f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs)\n\n        outputs = None\n        \n    return inputs, outputs\n\n# class ArgoverseDataset(Dataset):\n#     \"\"\"Dataset class for Argoverse\"\"\"\n#     def __init__(self, city: str, split:str, transform=None):\n#         super(ArgoverseDataset, self).__init__()\n#         self.transform = transform\n\n#         self.inputs, self.outputs, self.dit_int, self.dit_out = get_city_trajectories(city=city, split=split, normalized=False)\n\n#     def __len__(self):\n#         return len(self.inputs)\n\n#     def __getitem__(self, idx):\n\n#         data = (self.inputs[idx], self.outputs[idx])\n            \n#         if self.transform:\n#             data = self.transform(data)\n\n#         return data\n\n# # intialize a dataset example\n# city = 'palo-alto' \n# split = 'train'\n# train_dataset  = ArgoverseDataset(city = city, split = split)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:47.310663Z","iopub.execute_input":"2022-05-22T20:52:47.310906Z","iopub.status.idle":"2022-05-22T20:52:47.323659Z","shell.execute_reply.started":"2022-05-22T20:52:47.310878Z","shell.execute_reply":"2022-05-22T20:52:47.322841Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    \"\"\"Encoder Network.\"\"\"\n    def __init__(self,\n                 input_size: int = 2,\n                 embedding_size: int = 8,\n                 hidden_size: int = 16):\n        \"\"\"Initialize the encoder network.\n        Args:\n            input_size: number of features in the input\n            embedding_size: Embedding size\n            hidden_size: Hidden size of LSTM\n        \"\"\"\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.linear1 = nn.Linear(input_size, embedding_size)\n        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n\n    def forward(self, x: torch.FloatTensor, hidden):\n        \"\"\"Run forward propagation.\n        Args:\n            x: input to the network\n            hidden: initial hidden state\n        Returns:\n            hidden: final hidden \n        \"\"\"\n        embedded = F.relu(self.linear1(x))\n        hidden = self.lstm1(embedded, hidden)\n        return hidden\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:47.325083Z","iopub.execute_input":"2022-05-22T20:52:47.325317Z","iopub.status.idle":"2022-05-22T20:52:47.336774Z","shell.execute_reply.started":"2022-05-22T20:52:47.325291Z","shell.execute_reply":"2022-05-22T20:52:47.335814Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    \"\"\"Decoder Network.\"\"\"\n    def __init__(self, embedding_size=8, hidden_size=16, output_size=2):\n        \"\"\"Initialize the decoder network.\n        Args:\n            embedding_size: Embedding size\n            hidden_size: Hidden size of LSTM\n            output_size: number of features in the output\n        \"\"\"\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.linear1 = nn.Linear(output_size, embedding_size)\n        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n        self.linear2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden):\n        \"\"\"Run forward propagation.\n        Args:\n            x: input to the network\n            hidden: initial hidden state\n        Returns:\n            output: output from lstm\n            hidden: final hidden state\n        \"\"\"\n        embedded = F.relu(self.linear1(x))\n        hidden = self.lstm1(embedded, hidden)\n        output = self.linear2(hidden[0])\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:47.338144Z","iopub.execute_input":"2022-05-22T20:52:47.338409Z","iopub.status.idle":"2022-05-22T20:52:47.354735Z","shell.execute_reply.started":"2022-05-22T20:52:47.338377Z","shell.execute_reply":"2022-05-22T20:52:47.353656Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# convert the original training document into trainable batches \ndef get_batches(inp, out, batch_size):\n    \n    num_batches = int(len(inp) / (batch_size))\n    \n    X = inp[:num_batches*batch_size]\n    Y = out[:num_batches*batch_size]\n#     Y = np.zeros((len(X), 50))\n    \n    \n    # generate trainable batches\n    for i in range(0, num_batches*batch_size, batch_size):\n        Xs = []\n        Ys = []\n        for j in range(i, i+batch_size):\n            temp_x = X[j]\n               \n            temp_y = Y[j]\n            \n            Xs.append(temp_x)\n            Ys.append(temp_y)\n        \n        Xs = np.array(Xs)\n        Ys = np.array(Ys)\n\n        yield torch.tensor(Xs).float(), torch.tensor(Ys).float()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:52:52.558590Z","iopub.execute_input":"2022-05-22T20:52:52.558915Z","iopub.status.idle":"2022-05-22T20:52:52.567650Z","shell.execute_reply.started":"2022-05-22T20:52:52.558881Z","shell.execute_reply":"2022-05-22T20:52:52.566651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train_model(inp, out, n_epochs, hidden_size, batch_size, seq_size, lr, temperature):\n    \n    encoder = EncoderRNN(2, 8, hidden_size)\n    decoder = DecoderRNN(8, hidden_size, 2)\n    \n    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n    criterion = nn.MSELoss()\n    train_loss_over_time = []\n    epochs = []\n    for epoch in range(n_epochs):\n        \n        batches = get_batches(inp, out, batch_size)\n         \n        j = 0\n        print(\"new epoch starts, currently at \" + str(epoch) + \" epoch\")\n\n        \n        for X, Y in batches:\n            encoder.train()\n            decoder.train()\n\n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            \n            encoder_hidden = (torch.zeros(batch_size, hidden_size), torch.zeros(batch_size, hidden_size))\n    \n            loss = 0\n                \n            temp_x = X\n#             print(temp_x.shape)\n            temp_y = Y\n    \n            for i in range(len(temp_x[0])):\n                encoder_input = temp_x[:, i, :]\n                encoder_hidden = encoder(encoder_input, encoder_hidden)\n            \n            decoder_input = encoder_input[:, :2]\n            decoder_hidden = encoder_hidden\n            \n            \n            for i in range(60):\n                decoder_output, decoder_hidden = decoder(decoder_input,\n                                                     decoder_hidden)\n                \n#                 decoder_outputs[:, i, :] = decoder_output\n\n                # Update loss\n                loss += criterion(decoder_output[:, :2], temp_y[:, i, :2])\n\n                decoder_input = decoder_output\n \n\n            loss = loss / 60\n            \n            loss.backward()\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n            \n            j += 1\n        \n        print(decoder_output[:, :2][0])\n        print(temp_y[:, 59, :2][0])    \n        print(\"loss at last batch \" + str(j) + \" - \" + str(loss))\n        print(\"\\n\")  \n        \n        train_loss_over_time.append(loss.item())\n        epochs.append(epoch)\n    \n    \n    plt.plot(epochs, train_loss_over_time)\n    plt.xlabel(\"epoch num\")\n    plt.ylabel(\"train loss\")\n    return encoder, decoder","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:54:58.411365Z","iopub.execute_input":"2022-05-22T20:54:58.412266Z","iopub.status.idle":"2022-05-22T20:54:58.428751Z","shell.execute_reply.started":"2022-05-22T20:54:58.412211Z","shell.execute_reply":"2022-05-22T20:54:58.427634Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"p_i, p_o = get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:53:08.060914Z","iopub.execute_input":"2022-05-22T20:53:08.061192Z","iopub.status.idle":"2022-05-22T20:53:08.788299Z","shell.execute_reply.started":"2022-05-22T20:53:08.061164Z","shell.execute_reply":"2022-05-22T20:53:08.787292Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:53:09.619627Z","iopub.execute_input":"2022-05-22T20:53:09.619947Z","iopub.status.idle":"2022-05-22T20:53:09.624901Z","shell.execute_reply.started":"2022-05-22T20:53:09.619910Z","shell.execute_reply":"2022-05-22T20:53:09.623657Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# (inp, n_epochs, hidden_size, batch_size, seq_size, lr, temperature)\nstart = time.time()\nprint(\"Starts training process\")\nencoder, decoder = train_model(p_i, p_o, 20, 128, 500, 110, 0.05, 1.5)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:55:00.243852Z","iopub.execute_input":"2022-05-22T20:55:00.244146Z","iopub.status.idle":"2022-05-22T20:59:19.377472Z","shell.execute_reply.started":"2022-05-22T20:55:00.244118Z","shell.execute_reply":"2022-05-22T20:59:19.376633Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}