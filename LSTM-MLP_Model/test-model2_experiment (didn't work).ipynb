{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-21T21:38:14.112427Z",
     "iopub.status.busy": "2022-05-21T21:38:14.110047Z",
     "iopub.status.idle": "2022-05-21T21:38:14.160705Z",
     "shell.execute_reply": "2022-05-21T21:38:14.159684Z",
     "shell.execute_reply.started": "2022-05-21T21:38:14.112294Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T00:56:57.790407Z",
     "iopub.status.busy": "2022-05-21T00:56:57.789871Z",
     "iopub.status.idle": "2022-05-21T00:57:09.067531Z",
     "shell.execute_reply": "2022-05-21T00:57:09.06671Z",
     "shell.execute_reply.started": "2022-05-21T00:56:57.790358Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:38:14.162329Z",
     "iopub.status.busy": "2022-05-21T21:38:14.161883Z",
     "iopub.status.idle": "2022-05-21T21:38:16.880332Z",
     "shell.execute_reply": "2022-05-21T21:38:16.879321Z",
     "shell.execute_reply.started": "2022-05-21T21:38:14.162296Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:38:49.433461Z",
     "iopub.status.busy": "2022-05-21T21:38:49.432765Z",
     "iopub.status.idle": "2022-05-21T21:39:04.231528Z",
     "shell.execute_reply": "2022-05-21T21:39:04.230379Z",
     "shell.execute_reply.started": "2022-05-21T21:38:49.433414Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:10.149844Z",
     "iopub.status.busy": "2022-05-21T21:39:10.148847Z",
     "iopub.status.idle": "2022-05-21T21:39:10.170266Z",
     "shell.execute_reply": "2022-05-21T21:39:10.169173Z",
     "shell.execute_reply.started": "2022-05-21T21:39:10.149780Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"../input/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "        outputs = None\n",
    "    \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "        \n",
    "    elif split==\"test\":\n",
    "        f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "        outputs = None\n",
    "        \n",
    "    return inputs, outputs\n",
    "\n",
    "# class ArgoverseDataset(Dataset):\n",
    "#     \"\"\"Dataset class for Argoverse\"\"\"\n",
    "#     def __init__(self, city: str, split:str, transform=None):\n",
    "#         super(ArgoverseDataset, self).__init__()\n",
    "#         self.transform = transform\n",
    "\n",
    "#         self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.inputs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "#         data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "#         if self.transform:\n",
    "#             data = self.transform(data)\n",
    "\n",
    "#         return data\n",
    "\n",
    "# # intialize a dataset\n",
    "# count_train = 0\n",
    "# for i in cities:\n",
    "#     city = i  \n",
    "#     split = 'train'\n",
    "#     train_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "#     count_train += len(train_dataset)\n",
    "# print(\"the number of training data:\" + str(count_train))\n",
    "\n",
    "# count_test = 0\n",
    "# for i in cities:\n",
    "#     city = i  \n",
    "#     split = 'test'\n",
    "#     test_dataset  = ArgoverseDataset(city = city, split = split)\n",
    "#     count_test+= len(test_dataset)\n",
    "# print(\"the number of training data:\" + str(count_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:11.017876Z",
     "iopub.status.busy": "2022-05-21T21:39:11.017496Z",
     "iopub.status.idle": "2022-05-21T21:39:11.027099Z",
     "shell.execute_reply": "2022-05-21T21:39:11.026031Z",
     "shell.execute_reply.started": "2022-05-21T21:39:11.017838Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert the original training document into trainable batches \n",
    "def get_batches(inp, batch_size):\n",
    "    \n",
    "    num_batches = int(len(inp) / (batch_size))\n",
    "    \n",
    "    X = inp[:num_batches*batch_size]\n",
    "#     Y = np.zeros((len(X), 50))\n",
    "    \n",
    "    \n",
    "    # generate trainable batches\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for j in range(i, i+batch_size):\n",
    "            temp_x = X[j][:-1]\n",
    "               \n",
    "            temp_y = X[j][1:]\n",
    "            \n",
    "            Xs.append(temp_x)\n",
    "            Ys.append(temp_y)\n",
    "        \n",
    "        Xs = np.array(Xs)\n",
    "        Ys = np.array(Ys)\n",
    "\n",
    "        yield torch.tensor(Xs).float(), torch.tensor(Ys).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:12.150452Z",
     "iopub.status.busy": "2022-05-21T21:39:12.150064Z",
     "iopub.status.idle": "2022-05-21T21:39:12.168221Z",
     "shell.execute_reply": "2022-05-21T21:39:12.167181Z",
     "shell.execute_reply.started": "2022-05-21T21:39:12.150416Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN_new_1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=2):\n",
    "        super(RNN_new_1, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.encode1 = nn.Linear(input_size, hidden_size)\n",
    "        # input tensor - (batch, seq, tensor)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.bilstm = nn.LSTM(hidden_size, hidden_size//2, num_layers=n_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.encode2 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.encode3 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        \n",
    "        self.encode4 = nn.Linear(hidden_size * 2, hidden_size // 2)\n",
    "        \n",
    "        self.encode5 = nn.Linear(input_size, hidden_size // 2)\n",
    "        \n",
    "        self.encode6 = nn.Linear(hidden_size//2, output_size)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x_input, prev_hidden_and_cell, temperature=1.0):\n",
    "        \n",
    "        encode1 = self.encode1(x_input)\n",
    "\n",
    "#         print(encode1.unsqueeze(1).shape)\n",
    "        output, (hidden, cell) = self.lstm(encode1.unsqueeze(1), prev_hidden_and_cell)\n",
    "        \n",
    "        encode2 = self.encode2(x_input)\n",
    "        bi_output, (hidden, cell) = self.lstm(encode2.unsqueeze(1), prev_hidden_and_cell)\n",
    "#         print(bi_output.shape)\n",
    "        f_output = torch.tanh(self.encode3(output + bi_output))\n",
    "#         print(f_output.shape)\n",
    "        f_output1 = torch.tanh(self.encode4(f_output))\n",
    "#         print(f_output1.shape)\n",
    "        f_output2 = self.encode5(x_input)\n",
    "        \n",
    "        f_output2 = f_output2.reshape(f_output2.shape[0], 1, f_output2.shape[1])\n",
    "\n",
    "        output = self.encode6(f_output1 + f_output2)\n",
    "        output = output.reshape(len(output), 2)\n",
    "#         print(output.shape)\n",
    "\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        # return the initial hidden state and cell state\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:12.964544Z",
     "iopub.status.busy": "2022-05-21T21:39:12.964187Z",
     "iopub.status.idle": "2022-05-21T21:39:12.977389Z",
     "shell.execute_reply": "2022-05-21T21:39:12.976437Z",
     "shell.execute_reply.started": "2022-05-21T21:39:12.964509Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(inp, n_epochs, hidden_size, batch_size, seq_size, lr, temperature):\n",
    "    \n",
    "    # (input_size/feature dim, num of characters, hidden_size, output_size, n_layers=1)\n",
    "    model = RNN_new_1(2, hidden_size, 2, 1)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    avg_loss_over_time = []\n",
    "    for epoch in range(n_epochs):\n",
    "        batches = get_batches(inp, batch_size)\n",
    "\n",
    "        hidden, cell = model.init_state(batch_size)\n",
    "\n",
    "        i = 0\n",
    "        print(\"new epoch starts, currently at \" + str(epoch) + \" epoch\")\n",
    "        \n",
    "        loss_avg = 0\n",
    "        \n",
    "        for X, Y in batches:\n",
    "            i += 1\n",
    "\n",
    "            # Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = 0\n",
    "                         \n",
    "            for i in range(seq_size-1):\n",
    "                temp_x = X[:, i]\n",
    "                temp_y = Y[:, i]\n",
    "                output, (hidden, cell) = model.forward(temp_x.reshape(batch_size, 2), (hidden, cell), temperature)\n",
    "#                 print(output)\n",
    "#                 print(output.shape)\n",
    "                loss += criterion(output, temp_y.reshape(batch_size, 2))\n",
    "            \n",
    "            hidden = hidden.detach()\n",
    "            cell = cell.detach()\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            loss_avg += loss.item() / seq_size\n",
    "            \n",
    "        avg_loss_over_time.append(loss_avg / i)\n",
    "        print(\"avg loss at \" + str(i) + \"th iteration - \" + str(loss_avg / i))\n",
    "        print(\"\\n\")  \n",
    "    \n",
    "    \n",
    "    plt.plot(avg_loss_over_time)\n",
    "    plt.xlabel(\"epoch num\")\n",
    "    plt.ylabel(\"avg_loss\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:14.097982Z",
     "iopub.status.busy": "2022-05-21T21:39:14.097133Z",
     "iopub.status.idle": "2022-05-21T21:39:14.102073Z",
     "shell.execute_reply": "2022-05-21T21:39:14.101272Z",
     "shell.execute_reply.started": "2022-05-21T21:39:14.097929Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:14.890489Z",
     "iopub.status.busy": "2022-05-21T21:39:14.890107Z",
     "iopub.status.idle": "2022-05-21T21:39:15.286055Z",
     "shell.execute_reply": "2022-05-21T21:39:15.285397Z",
     "shell.execute_reply.started": "2022-05-21T21:39:14.890451Z"
    }
   },
   "outputs": [],
   "source": [
    "p_i, p_o = get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:15.727700Z",
     "iopub.status.busy": "2022-05-21T21:39:15.727083Z",
     "iopub.status.idle": "2022-05-21T21:39:15.744739Z",
     "shell.execute_reply": "2022-05-21T21:39:15.743789Z",
     "shell.execute_reply.started": "2022-05-21T21:39:15.727661Z"
    }
   },
   "outputs": [],
   "source": [
    "train_combined = np.concatenate([p_i, p_o], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:16.744905Z",
     "iopub.status.busy": "2022-05-21T21:39:16.744517Z",
     "iopub.status.idle": "2022-05-21T21:39:16.809736Z",
     "shell.execute_reply": "2022-05-21T21:39:16.808909Z",
     "shell.execute_reply.started": "2022-05-21T21:39:16.744861Z"
    }
   },
   "outputs": [],
   "source": [
    "p_test_i, p_test_o = get_city_trajectories(city=\"palo-alto\", split=\"test\", normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:17.801663Z",
     "iopub.status.busy": "2022-05-21T21:39:17.801005Z",
     "iopub.status.idle": "2022-05-21T21:39:17.811076Z",
     "shell.execute_reply": "2022-05-21T21:39:17.810159Z",
     "shell.execute_reply.started": "2022-05-21T21:39:17.801612Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(train_combined):\n",
    "    \n",
    "    x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n",
    "    x_std = np.std(train_combined[:, :, 0].reshape(-1))\n",
    "    x_norm = ((train_combined[:, :, 0].reshape(-1) - x_mean) / x_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n",
    "\n",
    "    y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n",
    "    y_std = np.std(train_combined[:, :, 1].reshape(-1))\n",
    "    y_norm = ((train_combined[:, :, 1].reshape(-1) - y_mean) / y_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n",
    "\n",
    "    normalized = np.concatenate([x_norm, y_norm], axis=2)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:18.910336Z",
     "iopub.status.busy": "2022-05-21T21:39:18.908927Z",
     "iopub.status.idle": "2022-05-21T21:39:18.991294Z",
     "shell.execute_reply": "2022-05-21T21:39:18.990122Z",
     "shell.execute_reply.started": "2022-05-21T21:39:18.910280Z"
    }
   },
   "outputs": [],
   "source": [
    "train_combined_norm = normalize(train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T21:39:24.446282Z",
     "iopub.status.busy": "2022-05-21T21:39:24.445793Z",
     "iopub.status.idle": "2022-05-21T21:52:23.499783Z",
     "shell.execute_reply": "2022-05-21T21:52:23.498753Z",
     "shell.execute_reply.started": "2022-05-21T21:39:24.446239Z"
    }
   },
   "outputs": [],
   "source": [
    "# (inp, n_epochs, hidden_size, batch_size, seq_size, lr, temperature)\n",
    "start = time.time()\n",
    "print(\"Starts training process\")\n",
    "model_1 = train_model(train_combined, 20, 128, 500, 110, 0.05, 1.5)\n",
    "end = time.time()\n",
    "print(\"Ends training process, total time - \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:06:46.745723Z",
     "iopub.status.busy": "2022-05-21T02:06:46.745241Z",
     "iopub.status.idle": "2022-05-21T02:06:46.76994Z",
     "shell.execute_reply": "2022-05-21T02:06:46.768982Z",
     "shell.execute_reply.started": "2022-05-21T02:06:46.745689Z"
    }
   },
   "outputs": [],
   "source": [
    "x_global_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n",
    "x_global_std = np.std(train_combined[:, :, 0].reshape(-1))\n",
    "y_global_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n",
    "y_global_std = np.std(train_combined[:, :, 1].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:19:49.323099Z",
     "iopub.status.busy": "2022-05-21T02:19:49.322831Z",
     "iopub.status.idle": "2022-05-21T02:19:49.33624Z",
     "shell.execute_reply": "2022-05-21T02:19:49.335342Z",
     "shell.execute_reply.started": "2022-05-21T02:19:49.323071Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, inp, predict_length, normalize_test_data=False):\n",
    "    \n",
    "    if normalize_test_data:\n",
    "        x_mean = np.mean(inp[:, 0].reshape(-1))\n",
    "        x_std = np.std(inp[:, 0].reshape(-1))\n",
    "        y_mean = np.mean(inp[:, 1].reshape(-1))\n",
    "        y_std = np.std(inp[:, 1].reshape(-1))\n",
    "        x_norm = ((inp[:, 0].reshape(-1) - x_mean) / x_std).reshape(inp.shape[0], 1)\n",
    "        y_norm = ((inp[:, 1].reshape(-1) - y_mean) / y_std).reshape(inp.shape[0], 1)\n",
    "\n",
    "        norm = np.concatenate([x_norm, y_norm], axis=1)\n",
    "    \n",
    "        inp = norm\n",
    "\n",
    "    \n",
    "    hidden, cell = model.init_state(1)\n",
    "    \n",
    "    \n",
    "    input_batch = get_batches(inp.reshape(1,len(inp),2), 1)\n",
    "\n",
    "    X, _ = next(input_batch)\n",
    "    \n",
    "    # build upon our hidden and cell state based on the first seq_size-1 positions\n",
    "    for i in range(len(inp)-1):\n",
    "        temp_x = X[:, i]\n",
    "#         print(temp_x)\n",
    "        output, (hidden, cell) = model.forward(temp_x, (hidden, cell))\n",
    "\n",
    "#         print(output)\n",
    "\n",
    "    prev = inp[-1]\n",
    "#     print(prev)\n",
    "    predict = []\n",
    "    # make the prediction character by character\n",
    "    for _ in range(predict_length):\n",
    "        \n",
    "        if _ == 0:\n",
    "            temp_x = torch.tensor([prev]).float()\n",
    "        else:\n",
    "            temp_x = prev\n",
    "       \n",
    "        output, (hidden, cell) = model.forward(temp_x, (hidden, cell))\n",
    "\n",
    "#         output = defined_softmax(output.reshape(1, 1, 61), temperature)\n",
    "\n",
    "        prev = output\n",
    "        \n",
    "        if normalize_test_data:\n",
    "            x_pred = (prev[0][0].item()) * x_std + x_mean\n",
    "            y_pred = (prev[0][1].item()) * y_std + y_mean\n",
    "        else:\n",
    "            x_pred = (prev[0][0].item())\n",
    "            y_pred = (prev[0][1].item())\n",
    "            \n",
    "        predict.append([x_pred, y_pred])\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:20:07.200065Z",
     "iopub.status.busy": "2022-05-21T02:20:07.19977Z",
     "iopub.status.idle": "2022-05-21T02:20:07.207931Z",
     "shell.execute_reply": "2022-05-21T02:20:07.207088Z",
     "shell.execute_reply.started": "2022-05-21T02:20:07.200032Z"
    }
   },
   "outputs": [],
   "source": [
    "p_o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:20:45.489179Z",
     "iopub.status.busy": "2022-05-21T02:20:45.488298Z",
     "iopub.status.idle": "2022-05-21T02:20:45.565319Z",
     "shell.execute_reply": "2022-05-21T02:20:45.564416Z",
     "shell.execute_reply.started": "2022-05-21T02:20:45.489127Z"
    }
   },
   "outputs": [],
   "source": [
    "predict(model_1, p_i[0], 60, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:21:43.457848Z",
     "iopub.status.busy": "2022-05-21T02:21:43.457393Z",
     "iopub.status.idle": "2022-05-21T02:23:42.532652Z",
     "shell.execute_reply": "2022-05-21T02:23:42.531705Z",
     "shell.execute_reply.started": "2022-05-21T02:21:43.457799Z"
    }
   },
   "outputs": [],
   "source": [
    "palo_df = pd.DataFrame()\n",
    "for i in range(len(p_test_i)):\n",
    "    \n",
    "    pred = predict(model_1, p_test_i[i], 60, False)\n",
    "    print(\"predicts for \" + str(i) + \" is done\")\n",
    "    temp_dict = {}\n",
    "    for j in range(0, 120, 2):\n",
    "        col_x = 'v' + str(j)\n",
    "        col_y = 'v' + str(j+1)\n",
    "        row = j // 2\n",
    "        temp_dict[col_x] = pred[row][0]\n",
    "        temp_dict[col_y] = pred[row][1]\n",
    "    \n",
    "    temp_idx_name = str(i) + \"_\" + \"palo-alto\"\n",
    "    temp_final = pd.DataFrame(temp_dict, index=[temp_idx_name])\n",
    "    palo_df = pd.concat([palo_df, temp_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:24:27.845599Z",
     "iopub.status.busy": "2022-05-21T02:24:27.845296Z",
     "iopub.status.idle": "2022-05-21T02:24:28.157526Z",
     "shell.execute_reply": "2022-05-21T02:24:28.156639Z",
     "shell.execute_reply.started": "2022-05-21T02:24:27.84557Z"
    }
   },
   "outputs": [],
   "source": [
    "palo_df.reset_index(level=0).rename(columns={\"index\": \"ID\"}).to_csv(\"model2_palo_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:25:22.846606Z",
     "iopub.status.busy": "2022-05-21T02:25:22.846319Z",
     "iopub.status.idle": "2022-05-21T02:25:22.963019Z",
     "shell.execute_reply": "2022-05-21T02:25:22.962196Z",
     "shell.execute_reply.started": "2022-05-21T02:25:22.846577Z"
    }
   },
   "outputs": [],
   "source": [
    "df_actual_path = \"../input/pred-actual/palo-alto_actual.csv\"\n",
    "df_pred_path = \"../input/pred1/model1_palo_df.csv\"\n",
    "\n",
    "def actual_error(df_actual_path, df_pred_path):\n",
    "    actual = pd.read_csv(df_actual_path)    \n",
    "    actual_array = actual.iloc[:, 1:].to_numpy()\n",
    "    \n",
    "    pred1 = pd.read_csv(df_pred_path)\n",
    "    pred1_array = pred1.iloc[:, 1:].to_numpy()\n",
    "    \n",
    "    return np.sum((actual_array - pred1_array)**2) / len(actual_array)\n",
    "\n",
    "actual_error(df_actual_path, df_pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:27:57.995774Z",
     "iopub.status.busy": "2022-05-21T02:27:57.995417Z",
     "iopub.status.idle": "2022-05-21T02:27:58.54544Z",
     "shell.execute_reply": "2022-05-21T02:27:58.544599Z",
     "shell.execute_reply.started": "2022-05-21T02:27:57.995739Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    " # create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:33:16.489694Z",
     "iopub.status.busy": "2022-05-21T02:33:16.489377Z",
     "iopub.status.idle": "2022-05-21T02:33:16.49498Z",
     "shell.execute_reply": "2022-05-21T02:33:16.494309Z",
     "shell.execute_reply.started": "2022-05-21T02:33:16.489659Z"
    }
   },
   "outputs": [],
   "source": [
    "p_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:34:40.132307Z",
     "iopub.status.busy": "2022-05-21T02:34:40.131976Z",
     "iopub.status.idle": "2022-05-21T02:34:40.138598Z",
     "shell.execute_reply": "2022-05-21T02:34:40.137686Z",
     "shell.execute_reply.started": "2022-05-21T02:34:40.132274Z"
    }
   },
   "outputs": [],
   "source": [
    "p_i[:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:35:26.999821Z",
     "iopub.status.busy": "2022-05-21T02:35:26.998765Z",
     "iopub.status.idle": "2022-05-21T02:35:27.007788Z",
     "shell.execute_reply": "2022-05-21T02:35:27.006431Z",
     "shell.execute_reply.started": "2022-05-21T02:35:26.999771Z"
    }
   },
   "outputs": [],
   "source": [
    "p_o[:, 0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:35:38.530594Z",
     "iopub.status.busy": "2022-05-21T02:35:38.529762Z",
     "iopub.status.idle": "2022-05-21T02:36:16.363208Z",
     "shell.execute_reply": "2022-05-21T02:36:16.362193Z",
     "shell.execute_reply.started": "2022-05-21T02:35:38.530546Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor.fit(p_i[:, :, 0], p_o[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:47:46.924957Z",
     "iopub.status.busy": "2022-05-21T02:47:46.923936Z",
     "iopub.status.idle": "2022-05-21T02:47:46.948875Z",
     "shell.execute_reply": "2022-05-21T02:47:46.947828Z",
     "shell.execute_reply.started": "2022-05-21T02:47:46.924914Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor.predict(p_i[0,:, 0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:16:55.049087Z",
     "iopub.status.busy": "2022-05-21T03:16:55.048764Z",
     "iopub.status.idle": "2022-05-21T03:16:55.056148Z",
     "shell.execute_reply": "2022-05-21T03:16:55.055201Z",
     "shell.execute_reply.started": "2022-05-21T03:16:55.049057Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(inp):\n",
    "    \n",
    "    final_feature = inp[:, :50, 0]\n",
    "    final_target = inp[:, 50, 0]\n",
    "    for i in range(1, 60):\n",
    "        temp_x = inp[:, i:50+i, 0]\n",
    "        temp_y = inp[:, 50+i, 0]\n",
    "        final_feature = np.concatenate([final_feature, temp_x], axis=0)\n",
    "        final_target = np.concatenate([final_target, temp_y], axis=0)\n",
    "    \n",
    "    return final_feature, final_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:17:10.736771Z",
     "iopub.status.busy": "2022-05-21T03:17:10.736332Z",
     "iopub.status.idle": "2022-05-21T03:17:13.220881Z",
     "shell.execute_reply": "2022-05-21T03:17:13.220009Z",
     "shell.execute_reply.started": "2022-05-21T03:17:10.736738Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = preprocess_data(train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:18:17.275718Z",
     "iopub.status.busy": "2022-05-21T03:18:17.27498Z",
     "iopub.status.idle": "2022-05-21T04:04:17.628171Z",
     "shell.execute_reply": "2022-05-21T04:04:17.626562Z",
     "shell.execute_reply.started": "2022-05-21T03:18:17.27568Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:52:50.617728Z",
     "iopub.status.busy": "2022-05-21T02:52:50.617084Z",
     "iopub.status.idle": "2022-05-21T02:52:50.624771Z",
     "shell.execute_reply": "2022-05-21T02:52:50.623794Z",
     "shell.execute_reply.started": "2022-05-21T02:52:50.617677Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_regressor(model, inp, pred_len):\n",
    "    \n",
    "    result = []\n",
    "    curr = inp[:, 0]\n",
    "    pred = model.predict(curr.reshape(1, -1))[0]\n",
    "    result.append(pred)\n",
    "    for i in range(1, pred_len):\n",
    "        curr = np.append(curr[1:], pred)\n",
    "        pred = model.predict(curr.reshape(1, -1))[0]\n",
    "        result.append(pred)\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
