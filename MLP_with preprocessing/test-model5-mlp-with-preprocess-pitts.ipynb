{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T20:21:00.571831Z","iopub.execute_input":"2022-05-23T20:21:00.572162Z","iopub.status.idle":"2022-05-23T20:21:00.586378Z","shell.execute_reply.started":"2022-05-23T20:21:00.572126Z","shell.execute_reply":"2022-05-23T20:21:00.585356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pickle5","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:36:54.237973Z","iopub.execute_input":"2022-05-23T21:36:54.238391Z","iopub.status.idle":"2022-05-23T21:37:05.339121Z","shell.execute_reply.started":"2022-05-23T21:36:54.238280Z","shell.execute_reply":"2022-05-23T21:37:05.338056Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os, os.path \nimport numpy \nimport pickle\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:05.341936Z","iopub.execute_input":"2022-05-23T21:37:05.342177Z","iopub.status.idle":"2022-05-23T21:37:07.980780Z","shell.execute_reply.started":"2022-05-23T21:37:05.342144Z","shell.execute_reply":"2022-05-23T21:37:07.979866Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport pickle5 as pickle\nimport numpy as np\n\nROOT_PATH = \"../input/\"\n\ncities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\nsplits = [\"train\", \"test\"]\n\ndef get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False, preprocess=False):\n    if split==\"train\":\n        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs).astype(np.float64)\n\n        outputs = None\n    \n        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n        outputs = pickle.load(open(f_out, \"rb\"))\n        outputs = np.asarray(outputs).astype(np.float64)\n        \n    elif split==\"test\":\n        f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs).astype(np.float64)\n\n        outputs = None\n    \n    if normalized:\n        train_combined = np.concatenate([inputs, outputs], axis=1)\n        x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n        x_std = np.std(train_combined[:, :, 0].reshape(-1))\n        x_norm = ((train_combined[:, :, 0].reshape(-1) - x_mean) / x_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n\n        y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n        y_std = np.std(train_combined[:, :, 1].reshape(-1))\n        y_norm = ((train_combined[:, :, 1].reshape(-1) - y_mean) / y_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n\n        normalized = np.concatenate([x_norm, y_norm], axis=2)\n        \n        return normalized[:, :50, :], normalized[:, 50:, :]\n\n    if preprocess:\n        preprocessed_inp = []\n        preprocessed_out = []\n        for i in range(inputs.shape[0]):\n            temp_i, temp_o = preprocess_single(inputs[i], outputs[i])\n            preprocessed_inp.append(temp_i)\n            preprocessed_out.append(temp_o)\n\n        preprocessed_inp = np.array(preprocessed_inp)\n        preprocessed_out = np.array(preprocessed_out)\n        \n        return preprocessed_inp, preprocessed_out\n    \n    return inputs, outputs\n\nclass ArgoverseDataset(Dataset):\n    \"\"\"Dataset class for Argoverse\"\"\"\n    def __init__(self, city: str, split:str, transform=None, normalize=False, preprocess=False):\n        super(ArgoverseDataset, self).__init__()\n        self.transform = transform\n\n        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=normalize, preprocess=preprocess)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n\n        data = (self.inputs[idx], self.outputs[idx])\n            \n        if self.transform:\n            data = self.transform(data)\n\n        return data\n\n# intialize a dataset\ncity = 'palo-alto' \nsplit = 'train'\ntrain_dataset  = ArgoverseDataset(city = city, split = split)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:07.982675Z","iopub.execute_input":"2022-05-23T21:37:07.983238Z","iopub.status.idle":"2022-05-23T21:37:08.795219Z","shell.execute_reply.started":"2022-05-23T21:37:07.983190Z","shell.execute_reply":"2022-05-23T21:37:08.794337Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:08.797382Z","iopub.execute_input":"2022-05-23T21:37:08.798669Z","iopub.status.idle":"2022-05-23T21:37:08.806297Z","shell.execute_reply.started":"2022-05-23T21:37:08.798551Z","shell.execute_reply":"2022-05-23T21:37:08.805466Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:08.808306Z","iopub.execute_input":"2022-05-23T21:37:08.809059Z","iopub.status.idle":"2022-05-23T21:37:08.819473Z","shell.execute_reply.started":"2022-05-23T21:37:08.809018Z","shell.execute_reply":"2022-05-23T21:37:08.818752Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Pred(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(100, 64),\n            nn.ReLU(),\n#             nn.Linear(64, 32),\n            nn.Linear(64, 16)\n#             nn.ReLU(),\n#             nn.Linear(32, 16),\n#             nn.ReLU(),\n#             nn.Linear(16, 16)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(16, 120),\n            nn.ReLU(),\n#             nn.Linear(32, 64),\n#             nn.ReLU(),\n#             nn.Linear(64, 128),\n#             nn.ReLU(),\n#             nn.Linear(128, 120),\n#             nn.ReLU(),\n            nn.Linear(120, 120)\n        )\n        \n    def forward(self, x):\n        x = x.reshape(-1, 100).float()\n        x = self.encoder(x)\n        x = self.decoder(x)\n#         print(\"------\")\n#         print(x.shape)\n        x = x.reshape(-1, 60, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:08.821226Z","iopub.execute_input":"2022-05-23T21:37:08.822434Z","iopub.status.idle":"2022-05-23T21:37:08.835125Z","shell.execute_reply.started":"2022-05-23T21:37:08.822374Z","shell.execute_reply":"2022-05-23T21:37:08.833940Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pred = Pred()\nopt = torch.optim.Adam(pred.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:08.836925Z","iopub.execute_input":"2022-05-23T21:37:08.838201Z","iopub.status.idle":"2022-05-23T21:37:08.862044Z","shell.execute_reply.started":"2022-05-23T21:37:08.838143Z","shell.execute_reply":"2022-05-23T21:37:08.861297Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"batch_sz = 512  # batch size \ncity = 'pittsburgh' \nsplit = 'train'\ntrain_dataset  = ArgoverseDataset(city = city, split = split, normalize=False, preprocess=True)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_sz)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:18.082023Z","iopub.execute_input":"2022-05-23T21:37:18.082971Z","iopub.status.idle":"2022-05-23T21:37:21.683080Z","shell.execute_reply.started":"2022-05-23T21:37:18.082908Z","shell.execute_reply":"2022-05-23T21:37:21.681953Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# p_i, p_o = get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False)\n# train_combined = np.concatenate([p_i, p_o], axis=1)\n# global_x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n# global_x_std = np.std(train_combined[:, :, 0].reshape(-1))\n# global_y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n# global_y_std = np.std(train_combined[:, :, 1].reshape(-1))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:42:55.703684Z","iopub.execute_input":"2022-05-23T05:42:55.704414Z","iopub.status.idle":"2022-05-23T05:42:55.740063Z","shell.execute_reply.started":"2022-05-23T05:42:55.704366Z","shell.execute_reply":"2022-05-23T05:42:55.739304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global_x_mean","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:43:05.134220Z","iopub.execute_input":"2022-05-23T05:43:05.134680Z","iopub.status.idle":"2022-05-23T05:43:05.139283Z","shell.execute_reply.started":"2022-05-23T05:43:05.134640Z","shell.execute_reply":"2022-05-23T05:43:05.138675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(pred):\n    loss_lst = []\n    for epoch in range(5000):\n        total_loss = 0\n        i = 0\n        for i_batch, sample_batch in enumerate(train_loader):\n            inp, out = sample_batch\n\n#             print(inp.shape)\n#             print(inp)\n            preds = pred(inp)\n#             print(preds.shape)\n#             print(out.shape)\n            loss = ((preds - out) ** 2).sum()\n\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            i += len(inp) * 60 * 2\n            \n            total_loss += loss.item()\n            \n        loss_lst.append(total_loss / i)\n        if epoch % 100 == 0:\n            print('epoch {} loss: {}'.format(epoch, total_loss / i))\n            \n    plt.plot(loss_lst)\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:24.983516Z","iopub.execute_input":"2022-05-23T21:37:24.983887Z","iopub.status.idle":"2022-05-23T21:37:24.991460Z","shell.execute_reply.started":"2022-05-23T21:37:24.983841Z","shell.execute_reply":"2022-05-23T21:37:24.990754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:25.924629Z","iopub.execute_input":"2022-05-23T21:37:25.925177Z","iopub.status.idle":"2022-05-23T21:37:25.930154Z","shell.execute_reply.started":"2022-05-23T21:37:25.925131Z","shell.execute_reply":"2022-05-23T21:37:25.929014Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel = train(pred)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:37:27.098877Z","iopub.execute_input":"2022-05-23T21:37:27.099198Z","iopub.status.idle":"2022-05-23T22:20:47.543109Z","shell.execute_reply.started":"2022-05-23T21:37:27.099164Z","shell.execute_reply":"2022-05-23T22:20:47.542470Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:23:51.618168Z","iopub.execute_input":"2022-05-23T22:23:51.618513Z","iopub.status.idle":"2022-05-23T22:23:51.625135Z","shell.execute_reply.started":"2022-05-23T22:23:51.618474Z","shell.execute_reply":"2022-05-23T22:23:51.624360Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"p_test_i, p_test_o = get_city_trajectories(city=\"pittsburgh\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:24:23.628749Z","iopub.execute_input":"2022-05-23T22:24:23.630077Z","iopub.status.idle":"2022-05-23T22:24:23.904576Z","shell.execute_reply.started":"2022-05-23T22:24:23.630017Z","shell.execute_reply":"2022-05-23T22:24:23.903899Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"p_test_i.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:24:26.155563Z","iopub.execute_input":"2022-05-23T22:24:26.156196Z","iopub.status.idle":"2022-05-23T22:24:26.162402Z","shell.execute_reply.started":"2022-05-23T22:24:26.156155Z","shell.execute_reply":"2022-05-23T22:24:26.161780Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# def normalize(p_test_i):\n#     return np.concatenate([((p_test_i[:, 0] - global_x_mean)/global_x_std).reshape(1,50,1), \\\n#                 ((p_test_i[:, 1] - global_y_mean)/global_y_std).reshape(1,50,1)], axis=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:43:39.898185Z","iopub.execute_input":"2022-05-23T05:43:39.898444Z","iopub.status.idle":"2022-05-23T05:43:39.904561Z","shell.execute_reply.started":"2022-05-23T05:43:39.898414Z","shell.execute_reply":"2022-05-23T05:43:39.903766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(torch.tensor(normalize(p_test_i[0])))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:44:00.894988Z","iopub.execute_input":"2022-05-23T05:44:00.895255Z","iopub.status.idle":"2022-05-23T05:44:00.906746Z","shell.execute_reply.started":"2022-05-23T05:44:00.895226Z","shell.execute_reply":"2022-05-23T05:44:00.905789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_1 = train(model)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:11:22.681379Z","iopub.execute_input":"2022-05-23T21:11:22.682162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_test_i, p_test_o = get_city_trajectories(city=\"palo-alto\", split=\"test\", normalized=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T01:46:35.488251Z","iopub.execute_input":"2022-05-23T01:46:35.488713Z","iopub.status.idle":"2022-05-23T01:46:35.499046Z","shell.execute_reply.started":"2022-05-23T01:46:35.488678Z","shell.execute_reply":"2022-05-23T01:46:35.498199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:58:04.392191Z","iopub.execute_input":"2022-05-23T05:58:04.392475Z","iopub.status.idle":"2022-05-23T05:58:04.398448Z","shell.execute_reply.started":"2022-05-23T05:58:04.392446Z","shell.execute_reply":"2022-05-23T05:58:04.397398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_2 = train(model_1)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:59:49.480732Z","iopub.execute_input":"2022-05-23T05:59:49.480987Z","iopub.status.idle":"2022-05-23T06:13:40.832715Z","shell.execute_reply.started":"2022-05-23T05:59:49.480959Z","shell.execute_reply":"2022-05-23T06:13:40.831939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_3 = train(model_2)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T06:19:57.766984Z","iopub.execute_input":"2022-05-23T06:19:57.767573Z","iopub.status.idle":"2022-05-23T06:33:48.150009Z","shell.execute_reply.started":"2022-05-23T06:19:57.767534Z","shell.execute_reply":"2022-05-23T06:33:48.149240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3","metadata":{"execution":{"iopub.status.busy":"2022-05-23T06:38:41.338700Z","iopub.execute_input":"2022-05-23T06:38:41.339049Z","iopub.status.idle":"2022-05-23T06:38:41.345292Z","shell.execute_reply.started":"2022-05-23T06:38:41.339009Z","shell.execute_reply":"2022-05-23T06:38:41.344524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_inp):\n    x_i = test_inp[0][0]\n    y_i = test_inp[0][1]\n    \n    pred = model(torch.tensor(preprocess_single(test_inp, None)[0]))[0]\n    \n    pred_x = pred[:, 0] + x_i\n    pred_y = pred[:, 1] + y_i\n    \n    return pred_x, pred_y","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:24:32.490755Z","iopub.execute_input":"2022-05-23T22:24:32.491199Z","iopub.status.idle":"2022-05-23T22:24:32.496808Z","shell.execute_reply.started":"2022-05-23T22:24:32.491165Z","shell.execute_reply":"2022-05-23T22:24:32.495932Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:24:34.031668Z","iopub.execute_input":"2022-05-23T22:24:34.032298Z","iopub.status.idle":"2022-05-23T22:24:34.038460Z","shell.execute_reply.started":"2022-05-23T22:24:34.032259Z","shell.execute_reply":"2022-05-23T22:24:34.037729Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(torch.tensor(preprocess_single(p_test_i[0], p_test_o)[0])).shape","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:01:13.397356Z","iopub.execute_input":"2022-05-23T21:01:13.397878Z","iopub.status.idle":"2022-05-23T21:01:13.407132Z","shell.execute_reply.started":"2022-05-23T21:01:13.397838Z","shell.execute_reply":"2022-05-23T21:01:13.406284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palo_df = pd.DataFrame()\nfor i in range(len(p_test_i)):\n    \n#     predict = model_3(torch.tensor(normalize(p_test_i[i])))\n    p_x, p_y = predict(model, p_test_i[i])\n    \n    if i % 100 == 0:\n        print(\"predicts for \" + str(i) + \" is done\")\n    temp_dict = {}\n    for j in range(0, 120, 2):\n        col_x = 'v' + str(j)\n        col_y = 'v' + str(j+1)\n        row = j // 2\n#         temp_dict[col_x] = predict[0][row][0].item() * global_x_std + global_x_mean\n#         temp_dict[col_y] = predict[0][row][1].item() * global_y_std + global_y_mean\n        temp_dict[col_x] = p_x[row].item()\n        temp_dict[col_y] = p_y[row].item()\n    \n    temp_idx_name = str(i) + \"_\" + \"pittsburgh\"\n    temp_final = pd.DataFrame(temp_dict, index=[temp_idx_name])\n    palo_df = pd.concat([palo_df, temp_final])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:24:55.731673Z","iopub.execute_input":"2022-05-23T22:24:55.731968Z","iopub.status.idle":"2022-05-23T22:25:28.034691Z","shell.execute_reply.started":"2022-05-23T22:24:55.731939Z","shell.execute_reply":"2022-05-23T22:25:28.033743Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"palo_df.reset_index(level=0).rename(columns={\"index\": \"ID\"}).to_csv(\"model5_pittsburgh.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:25:28.036438Z","iopub.execute_input":"2022-05-23T22:25:28.036777Z","iopub.status.idle":"2022-05-23T22:25:29.187355Z","shell.execute_reply.started":"2022-05-23T22:25:28.036732Z","shell.execute_reply":"2022-05-23T22:25:29.186445Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
