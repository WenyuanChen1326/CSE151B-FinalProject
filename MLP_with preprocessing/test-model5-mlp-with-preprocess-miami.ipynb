{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T20:21:00.571831Z","iopub.execute_input":"2022-05-23T20:21:00.572162Z","iopub.status.idle":"2022-05-23T20:21:00.586378Z","shell.execute_reply.started":"2022-05-23T20:21:00.572126Z","shell.execute_reply":"2022-05-23T20:21:00.585356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pickle5","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:34:50.098739Z","iopub.execute_input":"2022-05-23T21:34:50.099076Z","iopub.status.idle":"2022-05-23T21:35:05.162312Z","shell.execute_reply.started":"2022-05-23T21:34:50.099034Z","shell.execute_reply":"2022-05-23T21:35:05.160943Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os, os.path \nimport numpy \nimport pickle\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:05.164516Z","iopub.execute_input":"2022-05-23T21:35:05.164813Z","iopub.status.idle":"2022-05-23T21:35:08.214309Z","shell.execute_reply.started":"2022-05-23T21:35:05.164773Z","shell.execute_reply":"2022-05-23T21:35:08.213380Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport pickle5 as pickle\nimport numpy as np\n\nROOT_PATH = \"../input/\"\n\ncities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\nsplits = [\"train\", \"test\"]\n\ndef get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False, preprocess=False):\n    if split==\"train\":\n        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs).astype(np.float64)\n\n        outputs = None\n    \n        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n        outputs = pickle.load(open(f_out, \"rb\"))\n        outputs = np.asarray(outputs).astype(np.float64)\n        \n    elif split==\"test\":\n        f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n        inputs = pickle.load(open(f_in, \"rb\"))\n        inputs = np.asarray(inputs).astype(np.float64)\n\n        outputs = None\n    \n    if normalized:\n        train_combined = np.concatenate([inputs, outputs], axis=1)\n        x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n        x_std = np.std(train_combined[:, :, 0].reshape(-1))\n        x_norm = ((train_combined[:, :, 0].reshape(-1) - x_mean) / x_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n\n        y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n        y_std = np.std(train_combined[:, :, 1].reshape(-1))\n        y_norm = ((train_combined[:, :, 1].reshape(-1) - y_mean) / y_std).reshape(train_combined.shape[0], train_combined.shape[1], 1)\n\n        normalized = np.concatenate([x_norm, y_norm], axis=2)\n        \n        return normalized[:, :50, :], normalized[:, 50:, :]\n\n    if preprocess:\n        preprocessed_inp = []\n        preprocessed_out = []\n        for i in range(inputs.shape[0]):\n            temp_i, temp_o = preprocess_single(inputs[i], outputs[i])\n            preprocessed_inp.append(temp_i)\n            preprocessed_out.append(temp_o)\n\n        preprocessed_inp = np.array(preprocessed_inp)\n        preprocessed_out = np.array(preprocessed_out)\n        \n        return preprocessed_inp, preprocessed_out\n    \n    return inputs, outputs\n\nclass ArgoverseDataset(Dataset):\n    \"\"\"Dataset class for Argoverse\"\"\"\n    def __init__(self, city: str, split:str, transform=None, normalize=False, preprocess=False):\n        super(ArgoverseDataset, self).__init__()\n        self.transform = transform\n\n        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=normalize, preprocess=preprocess)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n\n        data = (self.inputs[idx], self.outputs[idx])\n            \n        if self.transform:\n            data = self.transform(data)\n\n        return data\n\n# intialize a dataset\ncity = 'palo-alto' \nsplit = 'train'\ntrain_dataset  = ArgoverseDataset(city = city, split = split)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.216908Z","iopub.execute_input":"2022-05-23T21:35:08.217387Z","iopub.status.idle":"2022-05-23T21:35:08.826668Z","shell.execute_reply.started":"2022-05-23T21:35:08.217345Z","shell.execute_reply":"2022-05-23T21:35:08.825566Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.828936Z","iopub.execute_input":"2022-05-23T21:35:08.829684Z","iopub.status.idle":"2022-05-23T21:35:08.837459Z","shell.execute_reply.started":"2022-05-23T21:35:08.829643Z","shell.execute_reply":"2022-05-23T21:35:08.836463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.838477Z","iopub.execute_input":"2022-05-23T21:35:08.838674Z","iopub.status.idle":"2022-05-23T21:35:08.855434Z","shell.execute_reply.started":"2022-05-23T21:35:08.838649Z","shell.execute_reply":"2022-05-23T21:35:08.854651Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Pred(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder = nn.Sequential(\n            nn.Linear(100, 64),\n            nn.ReLU(),\n#             nn.Linear(64, 32),\n            nn.Linear(64, 16)\n#             nn.ReLU(),\n#             nn.Linear(32, 16),\n#             nn.ReLU(),\n#             nn.Linear(16, 16)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(16, 120),\n            nn.ReLU(),\n#             nn.Linear(32, 64),\n#             nn.ReLU(),\n#             nn.Linear(64, 128),\n#             nn.ReLU(),\n#             nn.Linear(128, 120),\n#             nn.ReLU(),\n            nn.Linear(120, 120)\n        )\n        \n    def forward(self, x):\n        x = x.reshape(-1, 100).float()\n        x = self.encoder(x)\n        x = self.decoder(x)\n#         print(\"------\")\n#         print(x.shape)\n        x = x.reshape(-1, 60, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.856427Z","iopub.execute_input":"2022-05-23T21:35:08.856610Z","iopub.status.idle":"2022-05-23T21:35:08.867484Z","shell.execute_reply.started":"2022-05-23T21:35:08.856586Z","shell.execute_reply":"2022-05-23T21:35:08.866560Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pred = Pred()\nopt = torch.optim.Adam(pred.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.869178Z","iopub.execute_input":"2022-05-23T21:35:08.869368Z","iopub.status.idle":"2022-05-23T21:35:08.886794Z","shell.execute_reply.started":"2022-05-23T21:35:08.869344Z","shell.execute_reply":"2022-05-23T21:35:08.885901Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_sz = 512  # batch size \ncity = 'miami' \nsplit = 'train'\ntrain_dataset  = ArgoverseDataset(city = city, split = split, normalize=False, preprocess=True)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_sz)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:08.889844Z","iopub.execute_input":"2022-05-23T21:35:08.890206Z","iopub.status.idle":"2022-05-23T21:35:12.563294Z","shell.execute_reply.started":"2022-05-23T21:35:08.890170Z","shell.execute_reply":"2022-05-23T21:35:12.562150Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# p_i, p_o = get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False)\n# train_combined = np.concatenate([p_i, p_o], axis=1)\n# global_x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n# global_x_std = np.std(train_combined[:, :, 0].reshape(-1))\n# global_y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n# global_y_std = np.std(train_combined[:, :, 1].reshape(-1))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:42:55.703684Z","iopub.execute_input":"2022-05-23T05:42:55.704414Z","iopub.status.idle":"2022-05-23T05:42:55.740063Z","shell.execute_reply.started":"2022-05-23T05:42:55.704366Z","shell.execute_reply":"2022-05-23T05:42:55.739304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global_x_mean","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:43:05.134220Z","iopub.execute_input":"2022-05-23T05:43:05.134680Z","iopub.status.idle":"2022-05-23T05:43:05.139283Z","shell.execute_reply.started":"2022-05-23T05:43:05.134640Z","shell.execute_reply":"2022-05-23T05:43:05.138675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(pred):\n    loss_lst = []\n    for epoch in range(5000):\n        total_loss = 0\n        i = 0\n        for i_batch, sample_batch in enumerate(train_loader):\n            inp, out = sample_batch\n\n#             print(inp.shape)\n#             print(inp)\n            preds = pred(inp)\n#             print(preds.shape)\n#             print(out.shape)\n            loss = ((preds - out) ** 2).sum()\n\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            i += len(inp) * 60 * 2\n            \n            total_loss += loss.item()\n            \n        loss_lst.append(total_loss / i)\n        if epoch % 100 == 0:\n            print('epoch {} loss: {}'.format(epoch, total_loss / i))\n            \n    plt.plot(loss_lst)\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:17.618414Z","iopub.execute_input":"2022-05-23T21:35:17.618725Z","iopub.status.idle":"2022-05-23T21:35:17.627301Z","shell.execute_reply.started":"2022-05-23T21:35:17.618686Z","shell.execute_reply":"2022-05-23T21:35:17.626546Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:19.006763Z","iopub.execute_input":"2022-05-23T21:35:19.007421Z","iopub.status.idle":"2022-05-23T21:35:19.013090Z","shell.execute_reply.started":"2022-05-23T21:35:19.007378Z","shell.execute_reply":"2022-05-23T21:35:19.011689Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel = train(pred)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:35:21.109380Z","iopub.execute_input":"2022-05-23T21:35:21.110559Z","iopub.status.idle":"2022-05-23T22:43:02.223571Z","shell.execute_reply.started":"2022-05-23T21:35:21.110498Z","shell.execute_reply":"2022-05-23T22:43:02.222196Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:43:49.894857Z","iopub.execute_input":"2022-05-23T22:43:49.895251Z","iopub.status.idle":"2022-05-23T22:43:49.904459Z","shell.execute_reply.started":"2022-05-23T22:43:49.895211Z","shell.execute_reply":"2022-05-23T22:43:49.903096Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"p_test_i, p_test_o = get_city_trajectories(city=\"miami\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:44:12.311868Z","iopub.execute_input":"2022-05-23T22:44:12.312881Z","iopub.status.idle":"2022-05-23T22:44:12.636729Z","shell.execute_reply.started":"2022-05-23T22:44:12.312843Z","shell.execute_reply":"2022-05-23T22:44:12.635796Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"p_test_i.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:44:15.289445Z","iopub.execute_input":"2022-05-23T22:44:15.289848Z","iopub.status.idle":"2022-05-23T22:44:15.295395Z","shell.execute_reply.started":"2022-05-23T22:44:15.289816Z","shell.execute_reply":"2022-05-23T22:44:15.294508Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# def normalize(p_test_i):\n#     return np.concatenate([((p_test_i[:, 0] - global_x_mean)/global_x_std).reshape(1,50,1), \\\n#                 ((p_test_i[:, 1] - global_y_mean)/global_y_std).reshape(1,50,1)], axis=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:43:39.898185Z","iopub.execute_input":"2022-05-23T05:43:39.898444Z","iopub.status.idle":"2022-05-23T05:43:39.904561Z","shell.execute_reply.started":"2022-05-23T05:43:39.898414Z","shell.execute_reply":"2022-05-23T05:43:39.903766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(torch.tensor(normalize(p_test_i[0])))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:44:00.894988Z","iopub.execute_input":"2022-05-23T05:44:00.895255Z","iopub.status.idle":"2022-05-23T05:44:00.906746Z","shell.execute_reply.started":"2022-05-23T05:44:00.895226Z","shell.execute_reply":"2022-05-23T05:44:00.905789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_1 = train(model)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:11:22.681379Z","iopub.execute_input":"2022-05-23T21:11:22.682162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_test_i, p_test_o = get_city_trajectories(city=\"palo-alto\", split=\"test\", normalized=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T01:46:35.488251Z","iopub.execute_input":"2022-05-23T01:46:35.488713Z","iopub.status.idle":"2022-05-23T01:46:35.499046Z","shell.execute_reply.started":"2022-05-23T01:46:35.488678Z","shell.execute_reply":"2022-05-23T01:46:35.498199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:58:04.392191Z","iopub.execute_input":"2022-05-23T05:58:04.392475Z","iopub.status.idle":"2022-05-23T05:58:04.398448Z","shell.execute_reply.started":"2022-05-23T05:58:04.392446Z","shell.execute_reply":"2022-05-23T05:58:04.397398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_2 = train(model_1)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:59:49.480732Z","iopub.execute_input":"2022-05-23T05:59:49.480987Z","iopub.status.idle":"2022-05-23T06:13:40.832715Z","shell.execute_reply.started":"2022-05-23T05:59:49.480959Z","shell.execute_reply":"2022-05-23T06:13:40.831939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nmodel_3 = train(model_2)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-23T06:19:57.766984Z","iopub.execute_input":"2022-05-23T06:19:57.767573Z","iopub.status.idle":"2022-05-23T06:33:48.150009Z","shell.execute_reply.started":"2022-05-23T06:19:57.767534Z","shell.execute_reply":"2022-05-23T06:33:48.149240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3","metadata":{"execution":{"iopub.status.busy":"2022-05-23T06:38:41.338700Z","iopub.execute_input":"2022-05-23T06:38:41.339049Z","iopub.status.idle":"2022-05-23T06:38:41.345292Z","shell.execute_reply.started":"2022-05-23T06:38:41.339009Z","shell.execute_reply":"2022-05-23T06:38:41.344524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_inp):\n    x_i = test_inp[0][0]\n    y_i = test_inp[0][1]\n    \n    pred = model(torch.tensor(preprocess_single(test_inp, None)[0]))[0]\n    \n    pred_x = pred[:, 0] + x_i\n    pred_y = pred[:, 1] + y_i\n    \n    return pred_x, pred_y","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:44:22.905650Z","iopub.execute_input":"2022-05-23T22:44:22.905972Z","iopub.status.idle":"2022-05-23T22:44:22.911674Z","shell.execute_reply.started":"2022-05-23T22:44:22.905932Z","shell.execute_reply":"2022-05-23T22:44:22.910868Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:44:24.614323Z","iopub.execute_input":"2022-05-23T22:44:24.614622Z","iopub.status.idle":"2022-05-23T22:44:24.622895Z","shell.execute_reply.started":"2022-05-23T22:44:24.614587Z","shell.execute_reply":"2022-05-23T22:44:24.622046Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(torch.tensor(preprocess_single(p_test_i[0], p_test_o)[0])).shape","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:01:13.397356Z","iopub.execute_input":"2022-05-23T21:01:13.397878Z","iopub.status.idle":"2022-05-23T21:01:13.407132Z","shell.execute_reply.started":"2022-05-23T21:01:13.397838Z","shell.execute_reply":"2022-05-23T21:01:13.406284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palo_df = pd.DataFrame()\nfor i in range(len(p_test_i)):\n    \n#     predict = model_3(torch.tensor(normalize(p_test_i[i])))\n    p_x, p_y = predict(model, p_test_i[i])\n    \n    if i % 100 == 0:\n        print(\"predicts for \" + str(i) + \" is done\")\n    temp_dict = {}\n    for j in range(0, 120, 2):\n        col_x = 'v' + str(j)\n        col_y = 'v' + str(j+1)\n        row = j // 2\n#         temp_dict[col_x] = predict[0][row][0].item() * global_x_std + global_x_mean\n#         temp_dict[col_y] = predict[0][row][1].item() * global_y_std + global_y_mean\n        temp_dict[col_x] = p_x[row].item()\n        temp_dict[col_y] = p_y[row].item()\n    \n    temp_idx_name = str(i) + \"_\" + \"miami\"\n    temp_final = pd.DataFrame(temp_dict, index=[temp_idx_name])\n    palo_df = pd.concat([palo_df, temp_final])","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:44:37.259004Z","iopub.execute_input":"2022-05-23T22:44:37.259546Z","iopub.status.idle":"2022-05-23T22:45:20.161767Z","shell.execute_reply.started":"2022-05-23T22:44:37.259506Z","shell.execute_reply":"2022-05-23T22:45:20.160442Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"palo_df.reset_index(level=0).rename(columns={\"index\": \"ID\"}).to_csv(\"model5_miami.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T22:45:45.678701Z","iopub.execute_input":"2022-05-23T22:45:45.678982Z","iopub.status.idle":"2022-05-23T22:45:47.208014Z","shell.execute_reply.started":"2022-05-23T22:45:45.678951Z","shell.execute_reply":"2022-05-23T22:45:47.207111Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
