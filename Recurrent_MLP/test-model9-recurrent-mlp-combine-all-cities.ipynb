{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-31T05:20:43.65771Z","iopub.execute_input":"2022-05-31T05:20:43.658275Z","iopub.status.idle":"2022-05-31T05:20:43.72507Z","shell.execute_reply.started":"2022-05-31T05:20:43.658164Z","shell.execute_reply":"2022-05-31T05:20:43.723946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install pickle5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os, os.path \nimport numpy \nimport pickle\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:37:02.262179Z","iopub.execute_input":"2022-06-04T20:37:02.262828Z","iopub.status.idle":"2022-06-04T20:37:05.342076Z","shell.execute_reply.started":"2022-06-04T20:37:02.262740Z","shell.execute_reply":"2022-06-04T20:37:05.340922Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install pickle5","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:37:05.344241Z","iopub.execute_input":"2022-06-04T20:37:05.345047Z","iopub.status.idle":"2022-06-04T20:37:18.876294Z","shell.execute_reply.started":"2022-06-04T20:37:05.345003Z","shell.execute_reply":"2022-06-04T20:37:18.874566Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimport pickle5 as pickle\nimport numpy as np\n\nROOT_PATH = \"../input/\"\n\ncities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\nsplits = [\"train\", \"test\"]\n\ndef get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False, preprocess=False):\n    if city == \"all\" and split == \"train\":\n        all_inputs = None\n        all_outputs = None\n        for city in cities:\n            if all_inputs is None:\n                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n                inputs = pickle.load(open(f_in, \"rb\"))\n                all_inputs = np.asarray(inputs).astype(np.float64)\n            else:\n                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n                inputs = pickle.load(open(f_in, \"rb\"))\n                inputs = np.asarray(inputs).astype(np.float64)\n                all_inputs = np.concatenate([all_inputs, inputs], axis=0)\n\n            if all_outputs is None:\n                f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n                outputs = pickle.load(open(f_out, \"rb\"))\n                all_outputs = np.asarray(outputs).astype(np.float64)\n            else:\n                f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n                outputs = pickle.load(open(f_out, \"rb\"))\n                outputs = np.asarray(outputs).astype(np.float64)\n                all_outputs = np.concatenate([all_outputs, outputs], axis=0)\n            \n        inputs = all_inputs\n        outputs = all_outputs\n        \n    elif city == \"all\" and split==\"test\":\n        all_test_inputs = None\n        \n        for city in cities:\n            if all_test_inputs is None:\n                f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n                inputs = pickle.load(open(f_in, \"rb\"))\n                all_test_inputs = np.asarray(inputs).astype(np.float64)\n            else:\n                f_in = ROOT_PATH + \"test-inputs\" + \"/\" + city + \"_inputs\"\n                inputs = pickle.load(open(f_in, \"rb\"))\n                inputs = np.asarray(inputs).astype(np.float64)\n                all_test_inputs = np.concatenate([all_test_inputs, inputs], axis=0)\n\n        outputs = None\n        \n        inputs = all_test_inputs\n        \n\n    if preprocess:\n        preprocessed_inp = []\n        preprocessed_out = []\n        for i in range(inputs.shape[0]):\n            temp_i, temp_o = preprocess_single(inputs[i], outputs[i])\n            preprocessed_inp.append(temp_i)\n            preprocessed_out.append(temp_o)\n\n        preprocessed_inp = np.array(preprocessed_inp)\n        preprocessed_out = np.array(preprocessed_out)\n        \n        return preprocessed_inp, preprocessed_out\n    \n    return inputs, outputs\n\nclass ArgoverseDataset(Dataset):\n    \"\"\"Dataset class for Argoverse\"\"\"\n    def __init__(self, city: str, split:str, transform=None, normalize=False, preprocess=False):\n        super(ArgoverseDataset, self).__init__()\n        self.transform = transform\n\n        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=normalize, preprocess=preprocess)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n\n        data = (self.inputs[idx], self.outputs[idx])\n            \n        if self.transform:\n            data = self.transform(data)\n\n        return data","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:37:24.106828Z","iopub.execute_input":"2022-06-04T20:37:24.107462Z","iopub.status.idle":"2022-06-04T20:37:24.128243Z","shell.execute_reply.started":"2022-06-04T20:37:24.107421Z","shell.execute_reply":"2022-06-04T20:37:24.127417Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"inp, out = get_city_trajectories(city=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(num):\n    plt.plot(inp[num][:, 0], inp[num][:, 1], label=\"input\")\n    plt.plot(out[num][:, 0], out[num][:, 1], label=\"output\")\n    plt.title(\"Visualization of sample-{} of the entire training dataset\".format(num))\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:45:07.343483Z","iopub.execute_input":"2022-06-04T20:45:07.344156Z","iopub.status.idle":"2022-06-04T20:45:07.350102Z","shell.execute_reply.started":"2022-06-04T20:45:07.344101Z","shell.execute_reply":"2022-06-04T20:45:07.349017Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"plot_sample(20021)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T20:45:25.032701Z","iopub.execute_input":"2022-06-04T20:45:25.033073Z","iopub.status.idle":"2022-06-04T20:45:25.297817Z","shell.execute_reply.started":"2022-06-04T20:45:25.033042Z","shell.execute_reply":"2022-06-04T20:45:25.296994Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:01.264335Z","iopub.execute_input":"2022-05-31T05:21:01.264819Z","iopub.status.idle":"2022-05-31T05:21:01.273796Z","shell.execute_reply.started":"2022-05-31T05:21:01.264778Z","shell.execute_reply":"2022-05-31T05:21:01.271634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:01.286493Z","iopub.execute_input":"2022-05-31T05:21:01.287053Z","iopub.status.idle":"2022-05-31T05:21:01.299749Z","shell.execute_reply.started":"2022-05-31T05:21:01.287008Z","shell.execute_reply":"2022-05-31T05:21:01.298555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Pred(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder1 = nn.Sequential(\n            nn.Linear(862, 512),\n            nn.ReLU()\n#             nn.Dropout(0.5)\n        )\n        \n        self.encoder2 = nn.Sequential(\n            nn.Linear(862, 512),\n            nn.ReLU()\n#             nn.Dropout(0.5)\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(862, 512),\n            nn.ReLU(),\n            nn.Linear(862, 512)\n        )\n        \n        self.layer_norm = nn.LayerNorm(512)\n        \n        \n    def forward(self, x):\n        \n        x = x.to(device)\n        \n        x = x.reshape(-1, 350).float()\n        y = torch.zeros(len(x), 512)\n        \n        y = y.to(device)\n        \n        y = self.encoder1(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        y = self.encoder2(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        \n        y = self.encoder1(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        y = self.encoder2(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        \n        y = self.encoder1(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        y = self.encoder2(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        \n        y = self.encoder1(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        y = self.encoder2(torch.cat((x, y), 1))\n        y = self.layer_norm(y)\n        \n        output = self.decoder(torch.cat((x, y), 1))\n        \n        output = output.reshape(-1, 60, 2)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:12.137847Z","iopub.execute_input":"2022-05-31T05:21:12.13826Z","iopub.status.idle":"2022-05-31T05:21:12.154525Z","shell.execute_reply.started":"2022-05-31T05:21:12.138229Z","shell.execute_reply":"2022-05-31T05:21:12.153237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = Pred().to(device)\nopt = torch.optim.Adam(pred.parameters(), lr=0.0005)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:53:55.185302Z","iopub.execute_input":"2022-05-31T06:53:55.185785Z","iopub.status.idle":"2022-05-31T06:53:55.238548Z","shell.execute_reply.started":"2022-05-31T06:53:55.185729Z","shell.execute_reply":"2022-05-31T06:53:55.237291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_sz = 512  # batch size \n# city = 'palo-alto' \n# split = 'train'\n# train_dataset  = ArgoverseDataset(city = city, split = split, normalize=False, preprocess=True)\n# train_loader = DataLoader(train_dataset, batch_size=batch_sz)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T22:36:37.066748Z","iopub.execute_input":"2022-05-27T22:36:37.0673Z","iopub.status.idle":"2022-05-27T22:36:37.071795Z","shell.execute_reply.started":"2022-05-27T22:36:37.06726Z","shell.execute_reply":"2022-05-27T22:36:37.070922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_sz = 512  # batch size \ncity = \"all\" \nsplit = 'train'\ntrain_dataset  = ArgoverseDataset(city = city, split = split, normalize=False, preprocess=True)\n\ntrain_size = int(0.8 * len(train_dataset))\nvalid_size = len(train_dataset) - train_size\ntrain, valid = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n\ntrain_loader = DataLoader(train, batch_size=batch_sz)\nvalid_loader = DataLoader(valid, batch_size=batch_sz)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:19.555543Z","iopub.execute_input":"2022-05-31T05:21:19.557012Z","iopub.status.idle":"2022-05-31T05:21:32.641635Z","shell.execute_reply.started":"2022-05-31T05:21:19.556967Z","shell.execute_reply":"2022-05-31T05:21:32.640546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i, o = get_city_trajectories(city=\"all\", split=\"train\", normalized=False, preprocess=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T21:02:59.057993Z","iopub.execute_input":"2022-05-27T21:02:59.058492Z","iopub.status.idle":"2022-05-27T21:03:04.356267Z","shell.execute_reply.started":"2022-05-27T21:02:59.058443Z","shell.execute_reply":"2022-05-27T21:03:04.355434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# p_i, p_o = get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False)\n# train_combined = np.concatenate([p_i, p_o], axis=1)\n# global_x_mean = np.mean(train_combined[:, :, 0].reshape(-1))\n# global_x_std = np.std(train_combined[:, :, 0].reshape(-1))\n# global_y_mean = np.mean(train_combined[:, :, 1].reshape(-1))\n# global_y_std = np.std(train_combined[:, :, 1].reshape(-1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global_x_mean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_velocity(xy):\n    x = xy[:,:,0]\n    y = xy[:,:,1]\n    diff_x = torch.diff(x)/0.1\n    diff_y = torch.diff(y)/0.1\n    diff_x = torch.cat((diff_x, diff_x[:,-1:]),1).reshape(-1,50,1)\n    diff_y = torch.cat((diff_y, diff_y[:,-1:]),1).reshape(-1,50,1)\n    return torch.cat((x.reshape(-1,50,1),y.reshape(-1,50,1),diff_x,diff_y), 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.643596Z","iopub.execute_input":"2022-05-31T05:21:32.64406Z","iopub.status.idle":"2022-05-31T05:21:32.653765Z","shell.execute_reply.started":"2022-05-31T05:21:32.644014Z","shell.execute_reply":"2022-05-31T05:21:32.652405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_accel(xy):\n    x = xy[:,:,2]\n    y = xy[:,:,3]\n    diff_x = torch.diff(x)/0.1\n    diff_y = torch.diff(y)/0.1\n    diff_x = torch.cat((diff_x, diff_x[:,-1:]),1).reshape(-1,50,1)\n    diff_y = torch.cat((diff_y, diff_y[:,-1:]),1).reshape(-1,50,1)\n    return torch.cat((xy,diff_x,diff_y), 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.655463Z","iopub.execute_input":"2022-05-31T05:21:32.656586Z","iopub.status.idle":"2022-05-31T05:21:32.668335Z","shell.execute_reply.started":"2022-05-31T05:21:32.656532Z","shell.execute_reply":"2022-05-31T05:21:32.666944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_angular_velocity(xy):\n    x_i, x_f = xy[:,0,0], xy[:,-1,0]\n    y_i, y_f = xy[:,0,1], xy[:,-1,1]\n\n    radius = (((x_f - x_i)**2 + (y_f - y_i)**2)**0.5).reshape(len(xy), 1)   # shape of 512 x 1\n    \n#     broad_cast_radius = torch.tensor([[r] * 50 for r in radius]).to(device)  # shape of 512 x 50, the radius for each 50 timstamps is the same\n    broad_cast_radius = radius.expand(len(xy), 50).to(device)\n    \n    vx = xy[:,:,2]\n    vy = xy[:,:,3]\n    \n    vr = vx + vy\n    \n    w = (vr / broad_cast_radius).reshape(-1, 50, 1).to(device)\n    \n    return torch.cat((xy, w), 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.671387Z","iopub.execute_input":"2022-05-31T05:21:32.671957Z","iopub.status.idle":"2022-05-31T05:21:32.681572Z","shell.execute_reply.started":"2022-05-31T05:21:32.671912Z","shell.execute_reply":"2022-05-31T05:21:32.68041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_velocity_single(xy):\n    x = xy[:,0]\n    y = xy[:,1]\n    diff_x = torch.diff(x)/0.1\n    diff_y = torch.diff(y)/0.1\n    diff_x = torch.cat((diff_x, diff_x[-1:]),0).reshape(50,1)\n    diff_y = torch.cat((diff_y, diff_y[-1:]),0).reshape(50,1)\n    return torch.cat((x.reshape(50,1),y.reshape(50,1),diff_x,diff_y), 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.683361Z","iopub.execute_input":"2022-05-31T05:21:32.684648Z","iopub.status.idle":"2022-05-31T05:21:32.695118Z","shell.execute_reply.started":"2022-05-31T05:21:32.684513Z","shell.execute_reply":"2022-05-31T05:21:32.694063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_accel_single(xy):\n    x = xy[:,2]\n    y = xy[:,3]\n    diff_x = torch.diff(x)/0.1\n    diff_y = torch.diff(y)/0.1\n    diff_x = torch.cat((diff_x, diff_x[-1:]),0).reshape(50,1)\n    diff_y = torch.cat((diff_y, diff_y[-1:]),0).reshape(50,1)\n    return torch.cat((xy, diff_x, diff_y), 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.696526Z","iopub.execute_input":"2022-05-31T05:21:32.696868Z","iopub.status.idle":"2022-05-31T05:21:32.705949Z","shell.execute_reply.started":"2022-05-31T05:21:32.69684Z","shell.execute_reply":"2022-05-31T05:21:32.704816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_angular_single(xy):\n    x = xy[:,0]\n    y = xy[:,1]\n    \n    x_i, x_f = x[0], x[-1]\n    y_i, y_f = y[0], y[-1]\n    \n    radius = (((x_f - x_i)**2 + (y_f - y_i)**2)**0.5)\n    \n    vx = xy[:,2]\n    vy = xy[:,3]\n    \n    vr = (vx + vy)\n    \n    w = (vr / radius).reshape(50, 1)\n    \n    return torch.cat((xy, w), 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:21:32.707916Z","iopub.execute_input":"2022-05-31T05:21:32.70868Z","iopub.status.idle":"2022-05-31T05:21:32.720403Z","shell.execute_reply.started":"2022-05-31T05:21:32.708601Z","shell.execute_reply":"2022-05-31T05:21:32.719358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(pred):\n    loss_lst = []\n    valid_loss_lst = []\n    epochs = []\n    for epoch in range(20):\n        epochs.append(epoch)\n        total_loss = 0\n        i = 0\n        for i_batch, sample_batch in enumerate(train_loader):\n            inp, out = sample_batch\n\n#             print(inp.shape)\n#             print(inp)\n            inp = inp.to(device)\n            out = out.to(device)\n            inp = find_velocity(inp)\n            inp = find_accel(inp)\n            inp = find_angular_velocity(inp)\n        \n            preds = pred(inp)\n#             print(preds.shape)\n#             print(out.shape)\n\n            loss = ((preds - out) ** 2).sum().to(device)\n\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            i += len(inp) * 60 * 2\n            \n            total_loss += loss.item()\n            \n        loss_lst.append(total_loss / i)\n        if epoch >= 0:\n            print('epoch {} train loss: {}'.format(epoch, total_loss / i))\n        \n        \n            # calculate validation loss\n            total_valid_loss = 0\n            i = 0\n            for i_batch, sample_batch in enumerate(valid_loader):\n                inp, out = sample_batch\n                \n                inp = inp.to(device)\n                out = out.to(device)\n                \n                inp = find_velocity(inp)\n                inp = find_accel(inp)\n                inp = find_angular_velocity(inp)\n                \n        #             print(inp.shape)\n        #             print(inp)\n                preds_valid = pred(inp)\n        #             print(preds.shape)\n        #             print(out.shape)\n#                 inp = inp.to(device)\n#                 out = out.to(device)\n                valid_loss = ((preds_valid - out) ** 2).sum().to(device)\n\n                i += len(inp) * 60 * 2\n\n                total_valid_loss += loss.item()\n\n            valid_loss_lst.append(total_valid_loss / i)\n\n            print('epoch {} valid loss: {}'.format(epoch, total_valid_loss / i))\n            print('--------------------------------------------------------------')\n            print('\\n')\n                  \n    plt.plot(epochs, loss_lst, label=\"train_loss over time\")\n    plt.plot(epochs, valid_loss_lst, label=\"valid_loss over time\")\n    plt.legend()\n    \n    return epochs, loss_lst, valid_loss_lst","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:30:14.761406Z","iopub.execute_input":"2022-05-31T05:30:14.761867Z","iopub.status.idle":"2022-05-31T05:30:14.780209Z","shell.execute_reply.started":"2022-05-31T05:30:14.761835Z","shell.execute_reply":"2022-05-31T05:30:14.779008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:30:15.666478Z","iopub.execute_input":"2022-05-31T05:30:15.667001Z","iopub.status.idle":"2022-05-31T05:30:15.672536Z","shell.execute_reply.started":"2022-05-31T05:30:15.666952Z","shell.execute_reply":"2022-05-31T05:30:15.670872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\nprint(\"Starts training process\")\nepochs, loss_lst, valid_loss_lst = train(pred)\nend = time.time()\nprint(\"Ends training process, total time - \" + str(end - start))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:55:02.840519Z","iopub.execute_input":"2022-05-31T06:55:02.841329Z","iopub.status.idle":"2022-05-31T06:55:26.798459Z","shell.execute_reply.started":"2022-05-31T06:55:02.841293Z","shell.execute_reply":"2022-05-31T06:55:26.796949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss_lst, label=\"train_loss over time\")\nplt.plot(epochs, valid_loss_lst, label=\"valid_loss over time\")\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"MSE Loss\")\nplt.xticks(epochs)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:53:21.879482Z","iopub.execute_input":"2022-05-31T06:53:21.879939Z","iopub.status.idle":"2022-05-31T06:53:22.183592Z","shell.execute_reply.started":"2022-05-31T06:53:21.879907Z","shell.execute_reply":"2022-05-31T06:53:22.182568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_test_i, p_test_o = get_city_trajectories(city=\"all\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T20:59:51.002311Z","iopub.execute_input":"2022-05-28T20:59:51.003141Z","iopub.status.idle":"2022-05-28T20:59:51.794255Z","shell.execute_reply.started":"2022-05-28T20:59:51.003099Z","shell.execute_reply":"2022-05-28T20:59:51.793415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_test_i.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-28T20:59:52.398689Z","iopub.execute_input":"2022-05-28T20:59:52.399311Z","iopub.status.idle":"2022-05-28T20:59:52.405016Z","shell.execute_reply.started":"2022-05-28T20:59:52.399274Z","shell.execute_reply":"2022-05-28T20:59:52.404125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def normalize(p_test_i):\n#     return np.concatenate([((p_test_i[:, 0] - global_x_mean)/global_x_std).reshape(1,50,1), \\\n#                 ((p_test_i[:, 1] - global_y_mean)/global_y_std).reshape(1,50,1)], axis=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:43:39.898185Z","iopub.execute_input":"2022-05-23T05:43:39.898444Z","iopub.status.idle":"2022-05-23T05:43:39.904561Z","shell.execute_reply.started":"2022-05-23T05:43:39.898414Z","shell.execute_reply":"2022-05-23T05:43:39.903766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_inp):\n    \n    x_i = test_inp[0][0]\n    y_i = test_inp[0][1]\n    \n    test_inp = preprocess_single(test_inp, None)[0]\n    \n    test_inp = torch.tensor(test_inp).to(device)\n    test_inp = find_velocity_single(test_inp)\n    test_inp = find_accel_single(test_inp)\n    test_inp = find_angular_single(test_inp)\n    \n    pred = model(test_inp)[0]\n        \n    pred_x = pred[:, 0] + x_i\n    pred_y = pred[:, 1] + y_i\n    \n    return pred_x, pred_y","metadata":{"execution":{"iopub.status.busy":"2022-05-28T20:59:53.701015Z","iopub.execute_input":"2022-05-28T20:59:53.701367Z","iopub.status.idle":"2022-05-28T20:59:53.707881Z","shell.execute_reply.started":"2022-05-28T20:59:53.701338Z","shell.execute_reply":"2022-05-28T20:59:53.706881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here inp and out are single-target\ndef preprocess_single(inp, out):\n    x_i = inp[0][0]\n    y_i = inp[0][1]\n    \n    prep_inp = np.concatenate([(inp[:, 0] - x_i).reshape(50, 1), (inp[:, 1] - y_i).reshape(50, 1)], axis=1)\n    \n    if out is None:\n        return prep_inp, None\n\n    prep_out = np.concatenate([(out[:, 0] - x_i).reshape(60, 1), (out[:, 1] - y_i).reshape(60, 1)], axis=1)\n    \n    return prep_inp, prep_out","metadata":{"execution":{"iopub.status.busy":"2022-05-28T20:59:53.957849Z","iopub.execute_input":"2022-05-28T20:59:53.95813Z","iopub.status.idle":"2022-05-28T20:59:53.964869Z","shell.execute_reply.started":"2022-05-28T20:59:53.958105Z","shell.execute_reply":"2022-05-28T20:59:53.963847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palo_df = pd.DataFrame()\nfor i in range(len(p_test_i)):\n    \n#     predict = model_3(torch.tensor(normalize(p_test_i[i])))\n    p_x, p_y = predict(model, p_test_i[i])\n    \n    if i % 100 == 0:\n        print(\"predicts for \" + str(i) + \" is done\")\n    temp_dict = {}\n    for j in range(0, 120, 2):\n        col_x = 'v' + str(j)\n        col_y = 'v' + str(j+1)\n        row = j // 2\n#         temp_dict[col_x] = predict[0][row][0].item() * global_x_std + global_x_mean\n#         temp_dict[col_y] = predict[0][row][1].item() * global_y_std + global_y_mean\n        temp_dict[col_x] = p_x[row].item()\n        temp_dict[col_y] = p_y[row].item()\n    \n    temp_idx_name = str(i) + \"_\" + \"palo-alto\"\n    temp_final = pd.DataFrame(temp_dict, index=[temp_idx_name])\n    palo_df = pd.concat([palo_df, temp_final])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T06:06:37.475922Z","iopub.execute_input":"2022-05-27T06:06:37.476457Z","iopub.status.idle":"2022-05-27T06:06:50.851219Z","shell.execute_reply.started":"2022-05-27T06:06:37.476422Z","shell.execute_reply":"2022-05-27T06:06:50.850259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"palo_df.reset_index(level=0).rename(columns={\"index\": \"ID\"}).to_csv(\"model9.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T06:06:52.3Z","iopub.execute_input":"2022-05-27T06:06:52.30053Z","iopub.status.idle":"2022-05-27T06:06:52.655072Z","shell.execute_reply.started":"2022-05-27T06:06:52.300498Z","shell.execute_reply":"2022-05-27T06:06:52.654219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model9.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-05-27T06:10:23.055667Z","iopub.execute_input":"2022-05-27T06:10:23.056018Z","iopub.status.idle":"2022-05-27T06:10:23.067129Z","shell.execute_reply.started":"2022-05-27T06:10:23.055988Z","shell.execute_reply":"2022-05-27T06:10:23.06624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_model = Pred()\n# test_model.load_state_dict(torch.load(\"./mlp_with_preprocess_palo_alto.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T23:21:48.040325Z","iopub.execute_input":"2022-05-24T23:21:48.040642Z","iopub.status.idle":"2022-05-24T23:21:48.049179Z","shell.execute_reply.started":"2022-05-24T23:21:48.040602Z","shell.execute_reply":"2022-05-24T23:21:48.048458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
